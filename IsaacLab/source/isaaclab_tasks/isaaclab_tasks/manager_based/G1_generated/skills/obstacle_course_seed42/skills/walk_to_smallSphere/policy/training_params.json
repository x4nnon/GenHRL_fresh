{
  "skill_name": "walk_to_smallSphere",
  "checkpoint_path": "/home/tomcannon/Documents/GenHRL_v2/IsaacLab/logs/skrl/walk_to_smallsphere/2025-09-22_01-47-06_ppo_torch/checkpoints/agent_19000.pt",
  "saved_at": "1758503563.8126988",
  "model_architecture": {
    "layers": [
      {
        "layer_num": 0,
        "input_size": 362,
        "output_size": 256,
        "param_count": 92928
      },
      {
        "layer_num": 2,
        "input_size": 256,
        "output_size": 128,
        "param_count": 32896
      },
      {
        "layer_num": 4,
        "input_size": 128,
        "output_size": 64,
        "param_count": 8256
      },
      {
        "layer_num": 6,
        "input_size": 64,
        "output_size": 37,
        "param_count": 2405
      }
    ],
    "activation": "elu",
    "total_params": 136485,
    "input_dim": 362,
    "output_dim": 37
  },
  "agent_config": {
    "seed": 43,
    "models": {
      "separate": false,
      "policy": {
        "class": "GaussianMixin",
        "clip_actions": true,
        "clip_log_std": true,
        "min_log_std": -10.0,
        "max_log_std": 2.0,
        "initial_log_std": 0.0,
        "network": [
          {
            "name": "net",
            "input": "STATES",
            "layers": [
              256,
              128,
              64
            ],
            "activations": "elu"
          }
        ],
        "output": "ACTIONS"
      },
      "value": {
        "class": "DeterministicMixin",
        "clip_actions": false,
        "network": [
          {
            "name": "net",
            "input": "STATES",
            "layers": [
              256,
              128,
              64
            ],
            "activations": "elu"
          }
        ],
        "output": "ONE"
      }
    },
    "memory": {
      "class": "RandomMemory",
      "memory_size": -1
    },
    "agent": {
      "class": "PPO",
      "rollouts": 24,
      "learning_epochs": 5,
      "mini_batches": 4,
      "discount_factor": 0.99,
      "lambda": 0.95,
      "learning_rate": 0.001,
      "learning_rate_scheduler": "KLAdaptiveLR",
      "learning_rate_scheduler_kwargs": {
        "kl_threshold": 0.03,
        "min_lr": 0.0001,
        "max_lr": 0.001
      },
      "state_preprocessor": null,
      "state_preprocessor_kwargs": null,
      "value_preprocessor": null,
      "value_preprocessor_kwargs": null,
      "random_timesteps": 0,
      "learning_starts": 0,
      "grad_norm_clip": 1.0,
      "ratio_clip": 0.2,
      "value_clip": 0.2,
      "clip_predicted_values": true,
      "entropy_loss_scale": 0.05,
      "value_loss_scale": 1.0,
      "kl_threshold": 0.0,
      "rewards_shaper_scale": 1.0,
      "time_limit_bootstrap": false,
      "experiment": {
        "directory": "/home/tomcannon/Documents/GenHRL_v2/IsaacLab/logs/skrl/walk_to_smallsphere",
        "experiment_name": "2025-09-22_01-47-06_ppo_torch",
        "write_interval": "auto",
        "checkpoint_interval": 1000,
        "wandb": true,
        "wandb_kwargs": {
          "project": "genhrl_FlatObstacleCourseSeed42WalkToSmallsphere",
          "name": "2025-09-22_01-47-06_ppo_torch"
        }
      }
    },
    "trainer": {
      "class": "SequentialTrainer",
      "timesteps": 19992,
      "environment_info": "log",
      "close_environment_at_exit": false
    }
  }
}